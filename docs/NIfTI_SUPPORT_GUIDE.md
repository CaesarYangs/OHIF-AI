# OHIF-AI æ”¯æŒMSD(NIfTI)æ•°æ®æ ¼å¼å®ç°æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•è®©OHIF-AIæ”¯æŒç›´æ¥ä¸Šä¼ å’ŒåŠ è½½MSD(Medical Segmentation Decathlon)æ ¼å¼çš„`.nii.gz`æ–‡ä»¶ä½œä¸º3Dæ•°æ®è¾“å…¥ã€‚

---

## ğŸ“‹ ç›®å½•

1. [éœ€æ±‚åˆ†æ](#1-éœ€æ±‚åˆ†æ)
2. [æ¶æ„æ–¹æ¡ˆ](#2-æ¶æ„æ–¹æ¡ˆ)
3. [å‰ç«¯å®ç°](#3-å‰ç«¯å®ç°)
4. [åç«¯å®ç°](#4-åç«¯å®ç°)
5. [æ•°æ®æµæ”¹é€ ](#5-æ•°æ®æµæ”¹é€ )
6. [å®Œæ•´ä»£ç å®ç°](#6-å®Œæ•´ä»£ç å®ç°)
7. [æµ‹è¯•éªŒè¯](#7-æµ‹è¯•éªŒè¯)

---

## 1. éœ€æ±‚åˆ†æ

### å½“å‰ç³»ç»Ÿæ”¯æŒ
- âœ… DICOMæ ¼å¼ (é€šè¿‡Orthanc PACS)
- âœ… DICOM Web (WADO-RS)
- âŒ NIfTI (.nii, .nii.gz)

### MSDæ•°æ®é›†æ ¼å¼
```
Task03_Liver/
â”œâ”€â”€ imagesTr/           # è®­ç»ƒå›¾åƒ
â”‚   â”œâ”€â”€ liver_001.nii.gz
â”‚   â”œâ”€â”€ liver_002.nii.gz
â”‚   â””â”€â”€ ...
â”œâ”€â”€ labelsTr/           # è®­ç»ƒæ ‡ç­¾
â”‚   â”œâ”€â”€ liver_001.nii.gz
â”‚   â”œâ”€â”€ liver_002.nii.gz
â”‚   â””â”€â”€ ...
â”œâ”€â”€ imagesTs/           # æµ‹è¯•å›¾åƒ
â””â”€â”€ dataset.json        # æ•°æ®é›†æè¿°
```

### éœ€è¦å®ç°çš„åŠŸèƒ½
1. ç›´æ¥ä¸Šä¼  `.nii.gz` æ–‡ä»¶
2. è‡ªåŠ¨è¯†åˆ«NIfTIæ ¼å¼å¹¶åŠ è½½ä¸º3Dä½“ç§¯
3. åœ¨Cornerstone3Dä¸­æ˜¾ç¤º
4. AIæ¨¡å‹æ¨ç†æ”¯æŒ
5. ä¿å­˜åˆ†å‰²ç»“æœä¸ºNIfTI

---

## 2. æ¶æ„æ–¹æ¡ˆ

### æ•°æ®æµå¯¹æ¯”

```
å½“å‰DICOMæµç¨‹:
ç”¨æˆ·ä¸Šä¼ DICOM â†’ Orthancå­˜å‚¨ â†’ DICOM Webè¯·æ±‚ â†’ å‰ç«¯æ˜¾ç¤º â†’ AIæ¨ç†

æ–°çš„NIfTIæµç¨‹:
ç”¨æˆ·ä¸Šä¼ nii.gz â†’ åç«¯ç›´æ¥å­˜å‚¨ â†’ NIfTIåŠ è½½å™¨ â†’ å‰ç«¯æ˜¾ç¤º â†’ AIæ¨ç†
```

### ä¿®æ”¹æ¨¡å—æ¸…å•

| å±‚çº§ | æ¨¡å— | ä¿®æ”¹å†…å®¹ |
|-----|------|---------|
| å‰ç«¯ | DicomUploadç»„ä»¶ | æ”¯æŒnii.gzæ–‡ä»¶é€‰æ‹© |
| å‰ç«¯ | DataSource | æ·»åŠ NIfTIæ•°æ®æº |
| å‰ç«¯ | SOP Class Handler | æ·»åŠ NIfTIæ–‡ä»¶å¤„ç†å™¨ |
| å‰ç«¯ | Cornerstone | é…ç½®NIfTIä½“ç§¯åŠ è½½å™¨ |
| åç«¯ | Datastore | æ”¯æŒnii.gzæ–‡ä»¶å­˜å‚¨ |
| åç«¯ | File Parser | æ·»åŠ NIfTIå…ƒæ•°æ®æå– |
| åç«¯ | Infer Task | æ”¯æŒNIfTIæ–‡ä»¶è·¯å¾„è¾“å…¥ |
| åç«¯ | Writer | æ”¯æŒNIfTIæ ¼å¼è¾“å‡º |

---

## 3. å‰ç«¯å®ç°

### 3.1 ä¿®æ”¹æ–‡ä»¶ä¸Šä¼ ç»„ä»¶

**æ–‡ä»¶**: `Viewers/extensions/cornerstone/src/components/DicomUpload/DicomUpload.tsx`

```typescript
// ========== ä¿®æ”¹åçš„ä¸Šä¼ ç»„ä»¶ ==========
import React, { useState, useCallback } from 'react';
import { useDropzone } from 'react-dropzone';

interface UploadFile {
  file: File;
  progress: number;
  status: 'pending' | 'uploading' | 'success' | 'error';
}

// æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
const SUPPORTED_EXTENSIONS = {
  DICOM: ['.dcm', '.DCM'],
  NIFTI: ['.nii', '.nii.gz', '.nii.gz'],
  NRRD: ['.nrrd', '.nhdr'],
};

const NIfTIUploadComponent: React.FC<{
  servicesManager: ServicesManager;
  onUploadComplete: (displaySet: any) => void;
}> = ({ servicesManager, onUploadComplete }) => {
  const { uiNotificationService } = servicesManager.services;
  const [uploads, setUploads] = useState<UploadFile[]>([]);

  // æ£€æµ‹æ–‡ä»¶ç±»å‹
  const detectFileType = (file: File): 'dicom' | 'nifti' | 'nrrd' | 'unknown' => {
    const name = file.name.toLowerCase();
    
    if (name.endsWith('.dcm')) return 'dicom';
    if (name.endsWith('.nii') || name.endsWith('.nii.gz')) return 'nifti';
    if (name.endsWith('.nrrd') || name.endsWith('.nhdr')) return 'nrrd';
    
    return 'unknown';
  };

  // å¤„ç†NIfTIæ–‡ä»¶ä¸Šä¼ 
  const uploadNIfTIFile = async (file: File) => {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('contentType', 'application/gzip');
    
    try {
      const response = await fetch('/monai/datastore/nifti', {
        method: 'POST',
        body: formData,
      });
      
      if (!response.ok) {
        throw new Error(`Upload failed: ${response.statusText}`);
      }
      
      const result = await response.json();
      
      // åˆ›å»ºæ˜¾ç¤ºé›†
      const displaySet = await createNIfTIDisplaySet(result, file.name);
      
      onUploadComplete(displaySet);
      
      uiNotificationService.show({
        title: 'Upload Complete',
        message: `${file.name} uploaded successfully`,
        type: 'success',
      });
      
    } catch (error) {
      console.error('Upload error:', error);
      uiNotificationService.show({
        title: 'Upload Failed',
        message: error.message,
        type: 'error',
      });
    }
  };

  const onDrop = useCallback(async (acceptedFiles: File[]) => {
    for (const file of acceptedFiles) {
      const fileType = detectFileType(file);
      
      switch (fileType) {
        case 'dicom':
          // ç°æœ‰DICOMå¤„ç†é€»è¾‘
          await uploadDICOMFile(file);
          break;
          
        case 'nifti':
          // æ–°çš„NIfTIå¤„ç†é€»è¾‘
          await uploadNIfTIFile(file);
          break;
          
        case 'nrrd':
          // å¯é€‰ï¼šNRRDæ”¯æŒ
          await uploadNRRDFile(file);
          break;
          
        default:
          uiNotificationService.show({
            title: 'Unsupported File',
            message: `${file.name} is not a supported format`,
            type: 'warning',
          });
      }
    }
  }, []);

  const { getRootProps, getInputProps, isDragActive } = useDropzone({
    onDrop,
    accept: {
      'application/dicom': ['.dcm'],
      'application/gzip': ['.nii.gz'],
      'application/octet-stream': ['.nii', '.nrrd'],
    },
    multiple: true,
  });

  return (
    <div {...getRootProps()} className="upload-dropzone">
      <input {...getInputProps()} />
      <div className="upload-content">
        {isDragActive ? (
          <p>Drop the files here ...</p>
        ) : (
          <>
            <p>Drag & drop files here, or click to select</p>
            <p className="file-types">
              Supported: DICOM (.dcm), NIfTI (.nii, .nii.gz), NRRD (.nrrd)
            </p>
          </>
        )}
      </div>
      
      {/* ä¸Šä¼ è¿›åº¦åˆ—è¡¨ */}
      <div className="upload-progress-list">
        {uploads.map((upload, index) => (
          <div key={index} className={`upload-item ${upload.status}`}>
            <span className="file-name">{upload.file.name}</span>
            <div className="progress-bar">
              <div 
                className="progress-fill" 
                style={{ width: `${upload.progress}%` }}
              />
            </div>
            <span className="status">{upload.status}</span>
          </div>
        ))}
      </div>
    </div>
  );
};

export default NIfTIUploadComponent;
```

---

### 3.2 åˆ›å»ºNIfTIæ•°æ®æº

**æ–°å»ºæ–‡ä»¶**: `Viewers/extensions/default/src/NIfTIDataSource/index.ts`

```typescript
// ========== NIfTIæ•°æ®æºå®ç° ==========
import { utils, dataSources } from '@ohif/core';
import { createNIfTILoader } from './createNIfTILoader';

const { createStudyMetadata, createSeriesMetadata } = utils;

/**
 * NIfTIæ•°æ®æº
 * æ”¯æŒç›´æ¥åŠ è½½.niiå’Œ.nii.gzæ–‡ä»¶
 */
function createNIfTIDataSource(config: any) {
  const { name, configuration } = config;
  
  const dataSource = {
    name,
    type: 'nifti',
    
    /**
     * æŸ¥è¯¢ç ”ç©¶åˆ—è¡¨
     */
    queryStudies: async function(queryParams) {
      // ä»åç«¯è·å–å·²ä¸Šä¼ çš„NIfTIæ–‡ä»¶åˆ—è¡¨
      const response = await fetch('/monai/datastore/images?format=nifti');
      const niftiFiles = await response.json();
      
      return niftiFiles.map(file => ({
        studyInstanceUid: file.id,
        patientId: file.patientId || 'Unknown',
        patientName: file.patientName || 'Unknown',
        studyDate: file.uploadDate,
        studyDescription: file.description || `NIfTI: ${file.name}`,
        numSeries: 1,
        modalities: file.modality || 'CT',
      }));
    },
    
    /**
     * æŸ¥è¯¢åºåˆ—åˆ—è¡¨
     */
    querySeries: async function(studyInstanceUid) {
      const response = await fetch(`/monai/datastore/images/${studyInstanceUid}/series`);
      const seriesData = await response.json();
      
      return [{
        studyInstanceUid,
        seriesInstanceUid: seriesData.id,
        modality: seriesData.modality || 'CT',
        seriesNumber: 1,
        seriesDescription: seriesData.description || 'NIfTI Volume',
        numInstances: 1,
      }];
    },
    
    /**
     * è·å–ç³»åˆ—è¯¦æƒ…
     */
    getSeries: async function(studyInstanceUid, seriesInstanceUid) {
      const response = await fetch(
        `/monai/datastore/images/${studyInstanceUid}/series/${seriesInstanceUid}`
      );
      const seriesData = await response.json();
      
      return createSeriesMetadata({
        studyInstanceUid,
        seriesInstanceUid,
        ...seriesData,
      });
    },
    
    /**
     * è·å–å›¾åƒåŠ è½½å™¨
     */
    getImageLoaders: function() {
      return {
        nifti: createNIfTILoader(),
      };
    },
  };
  
  return dataSource;
}

export { createNIfTIDataSource };
```

---

### 3.3 åˆ›å»ºNIfTIåŠ è½½å™¨

**æ–°å»ºæ–‡ä»¶**: `Viewers/extensions/default/src/NIfTIDataSource/createNIfTILoader.ts`

```typescript
// ========== NIfTIå›¾åƒåŠ è½½å™¨ ==========
import * as cornerstone from '@cornerstonejs/core';
import { volumeLoader, imageLoader } from '@cornerstonejs/core';
import { parseNIfTIHeader, decodeNIfTIImage } from './niftiParser';

/**
 * åˆ›å»ºNIfTIåŠ è½½å™¨
 */
function createNIfTILoader() {
  const loader = {
    name: 'nifti',
    
    /**
     * æ£€æŸ¥æ˜¯å¦æ”¯æŒè¯¥URI
     */
    canLoadURI: function(uri: string) {
      return uri.toLowerCase().endsWith('.nii') || 
             uri.toLowerCase().endsWith('.nii.gz');
    },
    
    /**
     * åŠ è½½ä¸ºä½“ç§¯(Volume)
     */
    loadVolume: async function(volumeId: string) {
      // è§£ævolumeId: nifti:{fileId}
      const fileId = volumeId.replace('nifti:', '');
      
      // ä»åç«¯è·å–NIfTIæ–‡ä»¶
      const response = await fetch(`/monai/datastore/image/${fileId}`, {
        headers: { 'Accept': 'application/gzip' },
      });
      
      if (!response.ok) {
        throw new Error(`Failed to load NIfTI file: ${response.statusText}`);
      }
      
      // è·å–äºŒè¿›åˆ¶æ•°æ®
      const arrayBuffer = await response.arrayBuffer();
      
      // è§£æNIfTIå¤´ä¿¡æ¯
      const header = parseNIfTIHeader(arrayBuffer);
      
      // è§£ç å›¾åƒæ•°æ®
      const imageData = decodeNIfTIImage(arrayBuffer, header);
      
      // åˆ›å»ºCornerstoneä½“ç§¯
      const volume = await cornerstone.volumeLoader.createAndCacheVolume(volumeId, {
        // ç»´åº¦ [x, y, z]
        dimensions: header.dim.slice(1, 4),
        
        // ä½“ç´ é—´è· (mm)
        spacing: header.pixdim.slice(1, 4),
        
        // åŸç‚¹
        origin: header.qoffset || [0, 0, 0],
        
        // æ–¹å‘çŸ©é˜µ (ä»qform/sformè·å–)
        direction: header.getDirectionMatrix(),
        
        // æ•°æ®ç±»å‹
        scalarData: imageData,
        
        // å…¶ä»–å…ƒæ•°æ®
        metadata: {
          modality: header.intentName || 'CT',
          patientName: header.description || 'Unknown',
          seriesDescription: `NIfTI: ${header.description}`,
        },
      });
      
      return volume;
    },
    
    /**
     * åŠ è½½ä¸ºå•ä¸ªå›¾åƒ (ç”¨äºåˆ‡ç‰‡æ˜¾ç¤º)
     */
    loadImage: async function(imageId: string) {
      // è§£æ: nifti:{fileId}?slice={z}
      const url = new URL(imageId.replace('nifti:', 'http://localhost/'));
      const fileId = url.pathname;
      const sliceIndex = parseInt(url.searchParams.get('slice') || '0');
      
      // å…ˆåŠ è½½æ•´ä¸ªä½“ç§¯
      const volumeId = `nifti:${fileId}`;
      let volume = cornerstone.cache.getVolume(volumeId);
      
      if (!volume) {
        volume = await loader.loadVolume(volumeId);
      }
      
      // æå–æŒ‡å®šåˆ‡ç‰‡
      const sliceImage = await cornerstone.utilities.extractImageSlice(
        volume,
        sliceIndex
      );
      
      return sliceImage;
    },
  };
  
  return loader;
}

export { createNIfTILoader };
```

---

### 3.4 NIfTIè§£æå™¨

**æ–°å»ºæ–‡ä»¶**: `Viewers/extensions/default/src/NIfTIDataSource/niftiParser.ts`

```typescript
// ========== NIfTIæ–‡ä»¶è§£æå™¨ ==========
import { inflate } from 'pako';  // gzipè§£å‹

interface NIfTIHeader {
  // å¿…è¦å­—æ®µ
  dim: number[];           // ç»´åº¦ä¿¡æ¯ [dim0, x, y, z, ...]
  pixdim: number[];        // ä½“ç´ é—´è· [pix0, dx, dy, dz, ...]
  datatype: number;        // æ•°æ®ç±»å‹ä»£ç 
  bitpix: number;          // æ¯ä¸ªä½“ç´ çš„æ¯”ç‰¹æ•°
  
  // ç©ºé—´å˜æ¢
  qformCode: number;       // qformå˜æ¢ä»£ç 
  sformCode: number;       // sformå˜æ¢ä»£ç 
  quaternB: number;        // å››å…ƒæ•°å‚æ•°
  quaternC: number;
  quaternD: number;
  qoffsetX: number;        // åŸç‚¹åç§»
  qoffsetY: number;
  qoffsetZ: number;
  
  // æ–¹å‘çŸ©é˜µ (4x4)
  srowX: number[];
  srowY: number[];
  srowZ: number[];
  
  // å…¶ä»–
  intentCode: number;
  intentName: string;
  description: string;
  
  // è¾…åŠ©æ–¹æ³•
  getDirectionMatrix(): number[];
  getVoxelSize(): number[];
}

/**
 * è§£æNIfTIæ–‡ä»¶å¤´
 */
function parseNIfTIHeader(buffer: ArrayBuffer): NIfTIHeader {
  const dataView = new DataView(buffer);
  const isLittleEndian = true;
  
  // æ£€æŸ¥é­”æ•° (348æˆ–540)
  const sizeofHdr = dataView.getInt32(0, isLittleEndian);
  
  // æ£€æŸ¥æ˜¯å¦ä¸ºgzipå‹ç¼©
  const isGzipped = (new Uint8Array(buffer, 0, 2)[0] === 0x1f && 
                     new Uint8Array(buffer, 0, 2)[1] === 0x8b);
  
  let headerBuffer: ArrayBuffer;
  let dataBuffer: ArrayBuffer;
  
  if (isGzipped) {
    // è§£å‹gzip
    const inflated = inflate(new Uint8Array(buffer));
    headerBuffer = inflated.buffer;
    dataBuffer = inflated.buffer;
  } else {
    headerBuffer = buffer;
    dataBuffer = buffer;
  }
  
  const headerView = new DataView(headerBuffer);
  
  // è§£æç»´åº¦ä¿¡æ¯ (åç§»40)
  const dim = [];
  for (let i = 0; i < 8; i++) {
    dim.push(headerView.getInt16(40 + i * 2, isLittleEndian));
  }
  
  // è§£æä½“ç´ é—´è· (åç§»80)
  const pixdim = [];
  for (let i = 0; i < 8; i++) {
    pixdim.push(headerView.getFloat32(80 + i * 4, isLittleEndian));
  }
  
  // è§£ææ•°æ®ç±»å‹ (åç§»70)
  const datatype = headerView.getInt16(70, isLittleEndian);
  
  // è§£æqform/sform
  const qformCode = headerView.getInt16(252, isLittleEndian);
  const sformCode = headerView.getInt16(254, isLittleEndian);
  
  // è§£æå››å…ƒæ•°
  const quaternB = headerView.getFloat32(256, isLittleEndian);
  const quaternC = headerView.getFloat32(260, isLittleEndian);
  const quaternD = headerView.getFloat32(264, isLittleEndian);
  
  // è§£æåŸç‚¹åç§»
  const qoffsetX = headerView.getFloat32(268, isLittleEndian);
  const qoffsetY = headerView.getFloat32(272, isLittleEndian);
  const qoffsetZ = headerView.getFloat32(276, isLittleEndian);
  
  // è§£æsformçŸ©é˜µ (4x4, åç§»280)
  const srowX = [], srowY = [], srowZ = [];
  for (let i = 0; i < 4; i++) {
    srowX.push(headerView.getFloat32(280 + i * 4, isLittleEndian));
    srowY.push(headerView.getFloat32(296 + i * 4, isLittleEndian));
    srowZ.push(headerView.getFloat32(312 + i * 4, isLittleEndian));
  }
  
  // è§£ææè¿°
  const descriptionBytes = new Uint8Array(headerBuffer, 148, 80);
  const description = new TextDecoder().decode(descriptionBytes).replace(/\0/g, '');
  
  // æ•°æ®åç§» (é€šå¸¸ä¸º352æˆ–544)
  const voxOffset = headerView.getFloat32(108, isLittleEndian);
  
  return {
    dim,
    pixdim,
    datatype,
    bitpix: headerView.getInt16(72, isLittleEndian),
    qformCode,
    sformCode,
    quaternB,
    quaternC,
    quaternD,
    qoffsetX,
    qoffsetY,
    qoffsetZ,
    srowX,
    srowY,
    srowZ,
    intentCode: headerView.getInt16(68, isLittleEndian),
    intentName: '',  // ä»åç§»328è§£æ
    description,
    
    // è¾…åŠ©æ–¹æ³•
    getDirectionMatrix() {
      if (sformCode > 0) {
        // ä½¿ç”¨sform
        return [
          srowX[0], srowX[1], srowX[2],
          srowY[0], srowY[1], srowY[2],
          srowZ[0], srowZ[1], srowZ[2],
        ];
      } else if (qformCode > 0) {
        // ä½¿ç”¨qformè®¡ç®—æ–¹å‘çŸ©é˜µ
        return computeQFormMatrix(quaternB, quaternC, quaternD);
      }
      // é»˜è®¤å•ä½çŸ©é˜µ
      return [1, 0, 0, 0, 1, 0, 0, 0, 1];
    },
    
    getVoxelSize() {
      return [pixdim[1], pixdim[2], pixdim[3]];
    },
  };
}

/**
 * ä»å››å…ƒæ•°è®¡ç®—æ–¹å‘çŸ©é˜µ
 */
function computeQFormMatrix(b: number, c: number, d: number): number[] {
  // è®¡ç®—a (å››å…ƒæ•°å½’ä¸€åŒ–)
  const a = Math.sqrt(1.0 - (b * b + c * c + d * d));
  
  // æ„å»ºæ—‹è½¬çŸ©é˜µ
  const r11 = a * a + b * b - c * c - d * d;
  const r12 = 2 * b * c - 2 * a * d;
  const r13 = 2 * b * d + 2 * a * c;
  
  const r21 = 2 * b * c + 2 * a * d;
  const r22 = a * a + c * c - b * b - d * d;
  const r23 = 2 * c * d - 2 * a * b;
  
  const r31 = 2 * b * d - 2 * a * c;
  const r32 = 2 * c * d + 2 * a * b;
  const r33 = a * a + d * d - b * b - c * c;
  
  return [
    r11, r12, r13,
    r21, r22, r23,
    r31, r32, r33,
  ];
}

/**
 * è§£ç NIfTIå›¾åƒæ•°æ®
 */
function decodeNIfTIImage(buffer: ArrayBuffer, header: NIfTIHeader): Float32Array {
  // æ•°æ®åç§» (è·³è¿‡å¤´éƒ¨)
  const dataOffset = 352;  // æ ‡å‡†NIfTI-1å¤´éƒ¨å¤§å°
  
  // è®¡ç®—æ•°æ®å¤§å°
  const nx = header.dim[1];
  const ny = header.dim[2];
  const nz = header.dim[3];
  const dataSize = nx * ny * nz;
  
  // æ ¹æ®æ•°æ®ç±»å‹è§£ç 
  let data: Float32Array;
  
  switch (header.datatype) {
    case 2:  // DT_UNSIGNED_CHAR (8-bit)
      const u8 = new Uint8Array(buffer, dataOffset, dataSize);
      data = new Float32Array(dataSize);
      for (let i = 0; i < dataSize; i++) {
        data[i] = u8[i];
      }
      break;
      
    case 4:  // DT_SIGNED_SHORT (16-bit)
      const s16 = new Int16Array(buffer, dataOffset, dataSize);
      data = new Float32Array(dataSize);
      for (let i = 0; i < dataSize; i++) {
        data[i] = s16[i];
      }
      break;
      
    case 8:  // DT_SIGNED_INT (32-bit)
      const s32 = new Int32Array(buffer, dataOffset, dataSize);
      data = new Float32Array(dataSize);
      for (let i = 0; i < dataSize; i++) {
        data[i] = s32[i];
      }
      break;
      
    case 16:  // DT_FLOAT (32-bit float)
      data = new Float32Array(buffer, dataOffset, dataSize);
      break;
      
    case 64:  // DT_DOUBLE (64-bit double)
      const f64 = new Float64Array(buffer, dataOffset, dataSize);
      data = new Float32Array(dataSize);
      for (let i = 0; i < dataSize; i++) {
        data[i] = f64[i];
      }
      break;
      
    default:
      throw new Error(`Unsupported NIfTI datatype: ${header.datatype}`);
  }
  
  return data;
}

export { parseNIfTIHeader, decodeNIfTIImage, NIfTIHeader };
```

---

### 3.5 æ³¨å†ŒNIfTIæ•°æ®æº

**ä¿®æ”¹æ–‡ä»¶**: `Viewers/platform/app/src/App.tsx`

```typescript
// åœ¨æ•°æ®æºæ³¨å†Œéƒ¨åˆ†æ·»åŠ NIfTIæ”¯æŒ
import { createNIfTIDataSource } from '@ohif/extension-default/src/NIfTIDataSource';

function App() {
  useEffect(() => {
    // æ³¨å†Œæ•°æ®æº
    dataSourceManager.registerDataSource('dicomweb', createDicomWebDataSource(config));
    
    // æ³¨å†ŒNIfTIæ•°æ®æº
    dataSourceManager.registerDataSource('nifti', createNIfTIDataSource({
      name: 'nifti',
      configuration: {
        wadoRoot: '/monai/datastore',
      },
    }));
  }, []);
}
```

---

## 4. åç«¯å®ç°

### 4.1 æ·»åŠ NIfTIæ•°æ®å­˜å‚¨ç«¯ç‚¹

**ä¿®æ”¹æ–‡ä»¶**: `monai-label/monailabel/endpoints/datastore.py`

```python
# ========== æ·»åŠ NIfTIæ–‡ä»¶å¤„ç†ç«¯ç‚¹ ==========
import os
import uuid
import gzip
import shutil
from pathlib import Path
from fastapi import APIRouter, File, UploadFile, HTTPException
from fastapi.responses import FileResponse
import nibabel as nib
import numpy as np

router = APIRouter(
    prefix="/datastore",
    tags=["Datastore"],
)

# NIfTIæ–‡ä»¶å­˜å‚¨ç›®å½•
NIFTI_STORAGE_PATH = Path(os.environ.get("MONAI_LABEL_NIFTI_PATH", "/code/predictions/nifti"))
NIFTI_STORAGE_PATH.mkdir(parents=True, exist_ok=True)


@router.post("/nifti", summary="ä¸Šä¼ NIfTIæ–‡ä»¶")
async def upload_nifti_file(
    file: UploadFile = File(...),
    description: str = "",
):
    """
    ä¸Šä¼ NIfTI (.nii, .nii.gz) æ–‡ä»¶
    
    å‚æ•°:
        file: NIfTIæ–‡ä»¶
        description: æ–‡ä»¶æè¿°
    
    è¿”å›:
        {
            "id": æ–‡ä»¶ID,
            "name": æ–‡ä»¶å,
            "path": å­˜å‚¨è·¯å¾„,
            "dimensions": [x, y, z],
            "spacing": [dx, dy, dz],
            "modality": æ¨¡æ€ç±»å‹
        }
    """
    # éªŒè¯æ–‡ä»¶æ‰©å±•å
    filename = file.filename.lower()
    if not (filename.endswith('.nii') or filename.endswith('.nii.gz')):
        raise HTTPException(
            status_code=400,
            detail=f"Invalid file format. Expected .nii or .nii.gz, got {filename}"
        )
    
    # ç”Ÿæˆå”¯ä¸€ID
    file_id = str(uuid.uuid4())
    file_name = f"{file_id}.nii.gz"
    file_path = NIFTI_STORAGE_PATH / file_name
    
    try:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        with open(file_path, 'wb') as f:
            shutil.copyfileobj(file.file, f)
        
        # è§£æNIfTIå¤´ä¿¡æ¯
        header_info = parse_nifti_header(file_path)
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            "id": file_id,
            "name": file.filename,
            "path": str(file_path),
            "upload_date": datetime.now().isoformat(),
            "description": description,
            **header_info,
        }
        
        # ä¿å­˜å…ƒæ•°æ®åˆ°JSON
        meta_path = NIFTI_STORAGE_PATH / f"{file_id}.json"
        with open(meta_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        return metadata
        
    except Exception as e:
        # æ¸…ç†å¤±è´¥çš„æ–‡ä»¶
        if file_path.exists():
            file_path.unlink()
        raise HTTPException(status_code=500, detail=f"Failed to process NIfTI file: {str(e)}")


@router.get("/image/{file_id}", summary="è·å–NIfTIæ–‡ä»¶")
async def get_nifti_file(file_id: str):
    """è·å–NIfTIæ–‡ä»¶æ•°æ®"""
    file_path = NIFTI_STORAGE_PATH / f"{file_id}.nii.gz"
    
    if not file_path.exists():
        # å°è¯•éå‹ç¼©ç‰ˆæœ¬
        file_path = NIFTI_STORAGE_PATH / f"{file_id}.nii"
        if not file_path.exists():
            raise HTTPException(status_code=404, detail="File not found")
    
    return FileResponse(
        file_path,
        media_type='application/gzip',
        filename=file_path.name,
    )


@router.get("/images", summary="åˆ—å‡ºæ‰€æœ‰NIfTIæ–‡ä»¶")
async def list_nifti_files(
    format: str = "nifti",
    skip: int = 0,
    limit: int = 100,
):
    """åˆ—å‡ºå·²ä¸Šä¼ çš„NIfTIæ–‡ä»¶"""
    files = []
    
    for meta_file in NIFTI_STORAGE_PATH.glob("*.json"):
        with open(meta_file, 'r') as f:
            metadata = json.load(f)
            files.append(metadata)
    
    # æŒ‰ä¸Šä¼ æ—¥æœŸæ’åº
    files.sort(key=lambda x: x.get("upload_date", ""), reverse=True)
    
    return files[skip:skip + limit]


def parse_nifti_header(file_path: Path) -> dict:
    """
    è§£æNIfTIæ–‡ä»¶å¤´ä¿¡æ¯
    
    è¿”å›:
        {
            "dimensions": [x, y, z],
            "spacing": [dx, dy, dz],
            "origin": [ox, oy, oz],
            "direction": [...],
            "datatype": æ•°æ®ç±»å‹,
            "modality": æ¨¡æ€,
            "size_mb": æ–‡ä»¶å¤§å°(MB)
        }
    """
    try:
        # ä½¿ç”¨nibabelåŠ è½½
        img = nib.load(str(file_path))
        header = img.header
        
        # è·å–ç»´åº¦
        dimensions = list(img.shape[:3])  # å–å‰3ç»´
        
        # è·å–ä½“ç´ é—´è·
        spacing = header.get_zooms()[:3]
        
        # è·å–ä»¿å°„çŸ©é˜µ
        affine = img.affine
        
        # æå–åŸç‚¹å’Œæ–¹å‘
        origin = affine[:3, 3].tolist()
        
        # æå–æ–¹å‘çŸ©é˜µ (3x3)
        direction = [
            affine[0, 0], affine[0, 1], affine[0, 2],
            affine[1, 0], affine[1, 1], affine[1, 2],
            affine[2, 0], affine[2, 1], affine[2, 2],
        ]
        
        # æ•°æ®ç±»å‹
        datatype = int(header['datatype'])
        
        # å°è¯•ä»æè¿°ä¸­æå–æ¨¡æ€
        descrip = header.get('descrip', b'').decode('utf-8', errors='ignore').strip()
        modality = guess_modality(descrip, dimensions)
        
        # æ–‡ä»¶å¤§å°
        size_mb = file_path.stat().st_size / (1024 * 1024)
        
        return {
            "dimensions": dimensions,
            "spacing": list(spacing),
            "origin": origin,
            "direction": direction,
            "datatype": datatype,
            "modality": modality,
            "size_mb": round(size_mb, 2),
        }
        
    except Exception as e:
        raise ValueError(f"Failed to parse NIfTI header: {str(e)}")


def guess_modality(description: str, dimensions: list) -> str:
    """æ ¹æ®æè¿°å’Œç»´åº¦çŒœæµ‹æ¨¡æ€"""
    desc_lower = description.lower()
    
    if 'ct' in desc_lower or 'computerized' in desc_lower:
        return 'CT'
    elif 'mr' in desc_lower or 'mri' in desc_lower or 'magnetic' in desc_lower:
        return 'MR'
    elif 'pet' in desc_lower:
        return 'PT'
    elif 'us' in desc_lower or 'ultrasound' in desc_lower:
        return 'US'
    
    # æ ¹æ®ç»´åº¦çŒœæµ‹ (CT/MRé€šå¸¸æ˜¯512x512æˆ–æ›´é«˜)
    if dimensions[0] >= 256 and dimensions[1] >= 256:
        return 'CT'
    
    return 'OT'  # å…¶ä»–
```

---

### 4.2 ä¿®æ”¹æ¨ç†ä»»åŠ¡æ”¯æŒNIfTI

**ä¿®æ”¹æ–‡ä»¶**: `monai-label/monailabel/tasks/infer/basic_infer.py`

```python
# ========== åœ¨ __call__ æ–¹æ³•ä¸­æ·»åŠ NIfTIæ”¯æŒ ==========

def __call__(self, request, callbacks=None):
    """
    ä¸»æ¨ç†å…¥å£ï¼Œæ”¯æŒDICOMå’ŒNIfTIè¾“å…¥
    """
    req = copy.deepcopy(self._config)
    req.update(request)
    
    # æ£€æŸ¥è¾“å…¥ç±»å‹
    image_path = req.get("image", "")
    
    if image_path.endswith('.nii') or image_path.endswith('.nii.gz'):
        # NIfTIè¾“å…¥å¤„ç†
        return self._process_nifti(req)
    else:
        # DICOMè¾“å…¥å¤„ç† (åŸæœ‰é€»è¾‘)
        return self._process_dicom(req)


def _process_nifti(self, request: Dict) -> Tuple:
    """
    å¤„ç†NIfTIæ–‡ä»¶æ¨ç†
    
    ä¼˜åŠ¿:
    - æ— éœ€DICOMåˆ°NIfTIè½¬æ¢
    - ç›´æ¥åŠ è½½numpyæ•°ç»„
    - æ›´å¿«çš„é¢„å¤„ç†
    """
    import nibabel as nib
    
    nifti_path = request["image"]
    
    # 1. åŠ è½½NIfTIæ–‡ä»¶
    img = nib.load(nifti_path)
    img_np = img.get_fdata()
    
    # 2. ç¡®ä¿ç»´åº¦ä¸º (C, H, W, D)
    if img_np.ndim == 3:
        img_np = img_np[np.newaxis, ...]  # æ·»åŠ é€šé“ç»´
    elif img_np.ndim == 4:
        # å·²ç»æ˜¯4Dï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªé€šé“æˆ–å–å¹³å‡
        if img_np.shape[3] > 1:
            img_np = img_np[..., 0:1]  # å–ç¬¬ä¸€ä¸ªæ—¶é—´å¸§
        img_np = np.transpose(img_np, (3, 0, 1, 2))  # (H,W,D,C) -> (C,H,W,D)
    
    # 3. æ ‡å‡†åŒ–æ•°æ®ç±»å‹
    if img_np.dtype != np.float32:
        img_np = img_np.astype(np.float32)
    
    # 4. è·å–å…ƒæ•°æ®
    header = img.header
    spacing = header.get_zooms()[:3]
    origin = img.affine[:3, 3]
    
    logger.info(f"NIfTI loaded: shape={img_np.shape}, spacing={spacing}")
    
    # 5. æ ¹æ®é€‰æ‹©çš„æ¨¡å‹æ‰§è¡Œæ¨ç†
    model_type = request.get("nninter")
    
    if model_type == True or model_type == "nninter":
        return self._nninteractive_infer_nifti(img_np, request, spacing)
    elif not model_type:
        return self._sam_infer_nifti(img_np, request, spacing)
    else:
        return self._voxtell_infer_nifti(img_np, request)


def _nninteractive_infer_nifti(self, img_np: np.ndarray, request: Dict, spacing: tuple) -> Tuple:
    """
    ä½¿ç”¨nnInteractiveå¤„ç†NIfTIæ•°æ®
    """
    import nibabel as nib
    
    # nnInteractiveæœŸæœ›çš„è¾“å…¥æ ¼å¼: (1, Z, Y, X)
    if img_np.shape[0] != 1:
        # å¦‚æœæ˜¯å¤šé€šé“ï¼Œå–ç¬¬ä¸€ä¸ªæˆ–ä½¿ç”¨ç‰¹å®šé€šé“
        img_input = img_np[0:1, ...]
    else:
        img_input = img_np
    
    # è°ƒæ•´ç»´åº¦é¡ºåº (C, Z, Y, X) -> (1, Z, Y, X)
    # nibabelåŠ è½½çš„æ˜¯ (X, Y, Z) æˆ– (X, Y, Z, C)
    # æˆ‘ä»¬å·²ç»è½¬æ¢ä¸º (C, Z, Y, X)
    
    start_time = time.time()
    
    # åˆå§‹åŒ–nnInteractive (å¦‚æœå›¾åƒå˜åŒ–)
    series_id = request.get("image", "")
    if series_id != getattr(self, '_current_nifti_id', None):
        session.set_image(img_input)
        session.set_target_buffer(torch.zeros(img_input.shape[1:], dtype=torch.uint8))
        self._current_nifti_id = series_id
        self._session_used_interactions = {k: set() for k in self._session_used_interactions}
    
    # å¤„ç†æç¤º (ä¸DICOMç‰ˆæœ¬ç±»ä¼¼ï¼Œä½†æ— éœ€å¤„ç†DICOMæ–¹å‘)
    data = request
    result_json = {}
    
    # åæ ‡è½¬æ¢: NIfTIä½¿ç”¨æ•°ç»„ç´¢å¼•ï¼Œéœ€è¦æ³¨æ„Zè½´æ–¹å‘
    # NIfTIé€šå¸¸æ˜¯RASæ–¹å‘ï¼Œè€ŒnnInteractiveå¯èƒ½æœ‰ç‰¹å®šè¦æ±‚
    
    # æ­£ç‚¹æç¤º
    if len(data.get('pos_points', [])) != 0:
        result_json["pos_points"] = copy.deepcopy(data["pos_points"])
        for point in data['pos_points']:
            if not self.is_prompt_used(point, "pos_points"):
                self.add_prompt(point, "pos_points")
                # NIfTIåæ ‡é€šå¸¸æ˜¯ [x, y, z]ï¼Œéœ€è¦è½¬æ¢ä¸º [z, y, x] (numpyåˆ°nnInteractive)
                # æ³¨æ„: NIfTIçš„Zè½´æ–¹å‘å¯èƒ½éœ€è¦ç¿»è½¬
                nninteractive_point = (point[2], point[1], point[0])
                session.add_point_interaction(nninteractive_point, include_interaction=True)
    
    # æ¶‚é¸¦æç¤º
    if len(data.get('pos_scribbles', [])) != 0:
        result_json["pos_scribbles"] = copy.deepcopy(data["pos_scribbles"])
        for scribble in data['pos_scribbles']:
            if not self.is_prompt_used(scribble, "pos_scribbles"):
                self.add_prompt(scribble, "pos_scribbles")
                scribble = clean_and_densify_polyline(scribble)
                scribbleMask = np.zeros(img_input.shape[1:], dtype=np.uint8)
                
                # NIfTIåæ ‡è½¬æ¢
                filled_indices = np.round(np.asarray(scribble)).astype(int)
                z = filled_indices[:, 2]
                y = filled_indices[:, 1]
                x = filled_indices[:, 0]
                
                valid = (
                    (z >= 0) & (z < img_input.shape[1]) &
                    (y >= 0) & (y < img_input.shape[2]) &
                    (x >= 0) & (x < img_input.shape[3])
                )
                scribbleMask[z[valid], y[valid], x[valid]] = 1
                
                session.add_scribble_interaction(scribbleMask, include_interaction=True)
    
    # è¾¹ç•Œæ¡†æç¤º
    if len(data.get('pos_boxes', [])) != 0:
        result_json["pos_boxes"] = copy.deepcopy(data["pos_boxes"])
        for box in data['pos_boxes']:
            if not self.is_prompt_used(box, "pos_boxes"):
                self.add_prompt(box, "pos_boxes")
                # åæ ‡è½¬æ¢: [[x1,y1,z1], [x2,y2,z2]] -> [[z1,z2], [y1,y2], [x1,x2]]
                nninteractive_box = [
                    [box[0][2], box[1][2]],  # z
                    [box[0][1], box[1][1]],  # y
                    [box[0][0], box[1][0]],  # x
                ]
                session.add_bbox_interaction(nninteractive_box, include_interaction=True)
    
    # è·å–ç»“æœ
    results = session.target_buffer.clone()
    pred = results.numpy()
    
    elapsed = time.time() - start_time
    logger.info(f"nnInteractive NIfTI inference completed in {elapsed:.2f}s")
    
    # æ„å»ºè¿”å›ç»“æœ
    final_result = {
        "prompt_info": result_json,
        "nninter_elapsed": elapsed,
        "spacing": list(spacing),
    }
    
    # å¦‚æœéœ€è¦ï¼Œä¿å­˜ä¸ºNIfTIæ ¼å¼
    if request.get("output_format") == "nifti":
        output_path = self._save_as_nifti(pred, request["image"], spacing)
        return output_path, final_result
    
    return pred, final_result


def _save_as_nifti(self, data: np.ndarray, reference_path: str, spacing: tuple) -> str:
    """ä¿å­˜åˆ†å‰²ç»“æœä¸ºNIfTIæ ¼å¼"""
    import nibabel as nib
    from datetime import datetime
    
    # åŠ è½½å‚è€ƒå›¾åƒè·å–å…ƒæ•°æ®
    ref_img = nib.load(reference_path)
    
    # åˆ›å»ºæ–°çš„NIfTIå›¾åƒ
    # ç¡®ä¿æ•°æ®æ˜¯uint8
    if data.dtype != np.uint8:
        data = data.astype(np.uint8)
    
    # åˆ›å»ºNIfTIå›¾åƒ
    seg_img = nib.Nifti1Image(data, ref_img.affine, ref_img.header)
    
    # æ›´æ–°æè¿°
    seg_img.header['descrip'] = f'AI Segmentation {datetime.now().isoformat()}'
    
    # ä¿å­˜
    output_dir = Path("/code/predictions")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    output_path = output_dir / f"segmentation_{timestamp}.nii.gz"
    
    nib.save(seg_img, str(output_path))
    
    logger.info(f"Segmentation saved to {output_path}")
    
    return str(output_path)
```

---

### 4.3 æ·»åŠ NIfTIåˆ°æ•°æ®å­˜å‚¨æ¥å£

**ä¿®æ”¹æ–‡ä»¶**: `monai-label/monailabel/datastore/local.py`

```python
# ========== æ‰©å±•LocalDatastoreæ”¯æŒNIfTI ==========

class LocalDatastore(Datastore):
    """æ”¯æŒDICOMå’ŒNIfTIçš„æœ¬åœ°æ•°æ®å­˜å‚¨"""
    
    def __init__(self, path, extensions=None, **kwargs):
        # æ·»åŠ NIfTIæ‰©å±•å
        if extensions is None:
            extensions = [".nii.gz", ".nii", ".nrrd", ".dcm"]
        
        super().__init__(path, extensions=extensions, **kwargs)
        
        # NIfTIä¸“ç”¨å­˜å‚¨è·¯å¾„
        self._nifti_path = Path(path) / "nifti"
        self._nifti_path.mkdir(parents=True, exist_ok=True)
    
    def get_image_uri(self, image_id: str) -> str:
        """
        è·å–å›¾åƒæ–‡ä»¶è·¯å¾„
        æ”¯æŒDICOMç›®å½•æˆ–NIfTIæ–‡ä»¶
        """
        # æ£€æŸ¥æ˜¯å¦ä¸ºNIfTI ID (UUIDæ ¼å¼)
        if self._is_nifti_id(image_id):
            nifti_file = self._nifti_path / f"{image_id}.nii.gz"
            if nifti_file.exists():
                return str(nifti_file)
            
            # å°è¯•éå‹ç¼©ç‰ˆæœ¬
            nifti_file = self._nifti_path / f"{image_id}.nii"
            if nifti_file.exists():
                return str(nifti_file)
        
        # åŸæœ‰DICOMé€»è¾‘
        return super().get_image_uri(image_id)
    
    def _is_nifti_id(self, image_id: str) -> bool:
        """æ£€æŸ¥IDæ˜¯å¦ä¸ºNIfTIæ–‡ä»¶ID (UUIDæ ¼å¼)"""
        try:
            uuid.UUID(image_id)
            return True
        except ValueError:
            return False
    
    def add_nifti_image(self, file_path: Path, metadata: dict) -> str:
        """æ·»åŠ NIfTIå›¾åƒåˆ°å­˜å‚¨"""
        import shutil
        
        # ç”Ÿæˆå”¯ä¸€ID
        image_id = str(uuid.uuid4())
        
        # ç›®æ ‡è·¯å¾„
        target_path = self._nifti_path / f"{image_id}.nii.gz"
        
        # å¤åˆ¶æ–‡ä»¶
        shutil.copy(file_path, target_path)
        
        # ä¿å­˜å…ƒæ•°æ®
        meta_path = self._nifti_path / f"{image_id}.json"
        with open(meta_path, 'w') as f:
            json.dump(metadata, f)
        
        return image_id
```

---

## 5. æ•°æ®æµæ”¹é€ 

### 5.1 ä¸Šä¼ æµç¨‹å¯¹æ¯”

```
DICOMä¸Šä¼ æµç¨‹:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç”¨æˆ·é€‰æ‹© â”‚â”€â”€â”€â–¶â”‚  å‰ç«¯ä¸Šä¼    â”‚â”€â”€â”€â–¶â”‚  Orthanc    â”‚â”€â”€â”€â–¶â”‚  DICOM Web  â”‚
â”‚ DICOMæ–‡ä»¶â”‚    â”‚             â”‚    â”‚   PACS      â”‚    â”‚   åŠ è½½æ˜¾ç¤º  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NIfTIä¸Šä¼ æµç¨‹:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç”¨æˆ·é€‰æ‹© â”‚â”€â”€â”€â–¶â”‚  å‰ç«¯ä¸Šä¼    â”‚â”€â”€â”€â–¶â”‚ åç«¯ç›´æ¥    â”‚â”€â”€â”€â–¶â”‚  NIfTI      â”‚
â”‚ NIfTIæ–‡ä»¶â”‚    â”‚             â”‚    â”‚ å­˜å‚¨è§£æ    â”‚    â”‚ åŠ è½½å™¨æ˜¾ç¤º  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                                                â”‚
     â”‚         æ›´ç®€æ´ï¼Œæ— éœ€PACSä¸­è½¬                    â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 æ¨ç†æµç¨‹å¯¹æ¯”

```
DICOMæ¨ç†:
1. è¯»å–DICOMç›®å½•
2. ä½¿ç”¨SimpleITKè¯»å–ä¸ºImage
3. è½¬æ¢ä¸ºnumpy (Z, Y, X)
4. å¤„ç†DICOMæ–¹å‘ (å¯èƒ½éœ€è¦ç¿»è½¬)
5. æ‰§è¡ŒAIæ¨ç†
6. ç»“æœè½¬å›DICOMæ–¹å‘

NIfTIæ¨ç†:
1. ç›´æ¥è¯»å–.nii.gzæ–‡ä»¶
2. nibabelåŠ è½½ä¸ºnumpy
3. å·²ç»æ˜¯numpyæ•°ç»„
4. æ–¹å‘å·²ç¼–ç åœ¨affineçŸ©é˜µä¸­
5. æ‰§è¡ŒAIæ¨ç†
6. ç›´æ¥ä¿å­˜ä¸ºNIfTI (ä¿ç•™åŸaffine)
```

---

## 6. å®Œæ•´ä»£ç å®ç°

### 6.1 å‰ç«¯NIfTI SOP Class Handler

**æ–°å»ºæ–‡ä»¶**: `Viewers/extensions/cornerstone/src/getNIfTIHandler.ts`

```typescript
/**
 * NIfTIæ–‡ä»¶å¤„ç†å™¨
 * å°†NIfTIæ–‡ä»¶æ³¨å†Œä¸ºæ˜¾ç¤ºé›†
 */
import { SOPClassHandlerId } from './enums';

const NIfTI_LOADER_SCHEME = 'nifti';

function getNIfTISopClassHandler(servicesManager: ServicesManager) {
  const { displaySetService } = servicesManager.services;

  return {
    name: 'NIfTI',
    sopClassUids: ['1.2.840.10008.5.1.4.1.1.77.1.5'],  // ç§æœ‰SOP Class UID
    
    getDisplaySetsFromSeries: function(series) {
      const displaySet = {
        Modality: series.modality || 'CT',
        SeriesDescription: series.seriesDescription || 'NIfTI Volume',
        SeriesNumber: series.seriesNumber || 1,
        SeriesInstanceUID: series.seriesInstanceUid,
        StudyInstanceUID: series.studyInstanceUid,
        SOPClassHandlerId: 'NIfTI',
        SOPClassUID: '1.2.840.10008.5.1.4.1.1.77.1.5',
        
        // NIfTIç‰¹å®šå±æ€§
        url: `${NIfTI_LOADER_SCHEME}:${series.fileId}`,
        isReconstructable: true,
        is3D: true,
        
        // ç»´åº¦ä¿¡æ¯
        numImageFrames: series.dimensions?.[2] || 1,
        frameRate: 0,
        
        // åŠ è½½å™¨é…ç½®
        load: function() {
          return loadNIfTIDisplaySet(this, servicesManager);
        },
      };
      
      return [displaySet];
    },
  };
}

async function loadNIfTIDisplaySet(displaySet, servicesManager) {
  const { cornerstoneViewportService } = servicesManager.services;
  
  // ä½¿ç”¨NIfTIåŠ è½½å™¨åŠ è½½ä½“ç§¯
  const volumeId = displaySet.url;
  
  const volume = await cornerstone.volumeLoader.createAndCacheVolume(volumeId, {
    // ä½“ç§¯å±æ€§
  });
  
  await volume.load();
  
  return volume;
}

export default getNIfTISopClassHandler;
```

### 6.2 åç«¯æ‰¹é‡NIfTIå¯¼å…¥å·¥å…·

**æ–°å»ºæ–‡ä»¶**: `monai-label/monailabel/scripts/import_msd.py`

```python
#!/usr/bin/env python
"""
MSDæ•°æ®é›†å¯¼å…¥å·¥å…·
æ‰¹é‡å¯¼å…¥MSDæ ¼å¼çš„NIfTIæ–‡ä»¶

ä½¿ç”¨æ–¹æ³•:
    python import_msd.py --input /path/to/Task03_Liver --modality CT
"""

import argparse
import json
import os
from pathlib import Path
from typing import List, Dict
import nibabel as nib
import requests


def parse_msd_dataset(dataset_path: Path) -> Dict:
    """è§£æMSDæ•°æ®é›†ç»“æ„"""
    
    dataset_info = {
        "name": dataset_path.name,
        "imagesTr": [],
        "labelsTr": [],
        "imagesTs": [],
    }
    
    # è¯»å–dataset.json
    json_file = dataset_path / "dataset.json"
    if json_file.exists():
        with open(json_file, 'r') as f:
            msd_info = json.load(f)
            dataset_info.update(msd_info)
    
    # æ‰«æimagesTrç›®å½•
    images_tr_dir = dataset_path / "imagesTr"
    if images_tr_dir.exists():
        dataset_info["imagesTr"] = sorted([
            f.name for f in images_tr_dir.glob("*.nii.gz")
        ])
    
    # æ‰«ælabelsTrç›®å½•
    labels_tr_dir = dataset_path / "labelsTr"
    if labels_tr_dir.exists():
        dataset_info["labelsTr"] = sorted([
            f.name for f in labels_tr_dir.glob("*.nii.gz")
        ])
    
    return dataset_info


def import_nifti_to_monai(
    file_path: Path,
    server_url: str = "http://localhost:8002",
    description: str = "",
) -> str:
    """
    å¯¼å…¥å•ä¸ªNIfTIæ–‡ä»¶åˆ°MONAI Label
    
    è¿”å›:
        æ–‡ä»¶ID
    """
    import requests
    
    url = f"{server_url}/monai/datastore/nifti"
    
    with open(file_path, 'rb') as f:
        files = {'file': (file_path.name, f, 'application/gzip')}
        data = {'description': description}
        
        response = requests.post(url, files=files, data=data)
        response.raise_for_status()
        
        result = response.json()
        return result["id"]


def batch_import_msd(
    dataset_path: Path,
    server_url: str = "http://localhost:8002",
    import_labels: bool = True,
):
    """æ‰¹é‡å¯¼å…¥MSDæ•°æ®é›†"""
    
    dataset_info = parse_msd_dataset(dataset_path)
    print(f"Importing MSD dataset: {dataset_info['name']}")
    print(f"Training images: {len(dataset_info['imagesTr'])}")
    print(f"Training labels: {len(dataset_info['labelsTr'])}")
    
    imported = []
    
    # å¯¼å…¥è®­ç»ƒå›¾åƒ
    images_tr_dir = dataset_path / "imagesTr"
    for img_name in dataset_info['imagesTr']:
        img_path = images_tr_dir / img_name
        
        try:
            file_id = import_nifti_to_monai(
                img_path,
                server_url,
                description=f"MSD {dataset_info['name']}: {img_name}"
            )
            
            imported.append({
                "name": img_name,
                "id": file_id,
                "type": "image",
            })
            
            print(f"âœ“ Imported: {img_name} -> {file_id}")
            
        except Exception as e:
            print(f"âœ— Failed to import {img_name}: {e}")
    
    # å¯¼å…¥æ ‡ç­¾ (å¯é€‰)
    if import_labels and dataset_info['labelsTr']:
        labels_tr_dir = dataset_path / "labelsTr"
        for label_name in dataset_info['labelsTr']:
            label_path = labels_tr_dir / label_name
            
            try:
                # æ ‡ç­¾ä½œä¸ºå·²æœ‰å›¾åƒçš„æ ‡ç­¾ä¸Šä¼ 
                # éœ€è¦åŒ¹é…å›¾åƒID
                pass
                
            except Exception as e:
                print(f"âœ— Failed to import label {label_name}: {e}")
    
    # ä¿å­˜å¯¼å…¥è®°å½•
    output_file = dataset_path / "imported_monai.json"
    with open(output_file, 'w') as f:
        json.dump(imported, f, indent=2)
    
    print(f"\nImport complete! {len(imported)} files imported.")
    print(f"Import record saved to: {output_file}")


def main():
    parser = argparse.ArgumentParser(description="Import MSD dataset to MONAI Label")
    parser.add_argument("--input", "-i", required=True, help="MSD dataset path")
    parser.add_argument("--server", "-s", default="http://localhost:8002", 
                        help="MONAI Label server URL")
    parser.add_argument("--no-labels", action="store_true", 
                        help="Skip importing labels")
    
    args = parser.parse_args()
    
    dataset_path = Path(args.input)
    if not dataset_path.exists():
        print(f"Error: Dataset path does not exist: {dataset_path}")
        return
    
    batch_import_msd(
        dataset_path,
        server_url=args.server,
        import_labels=not args.no_labels,
    )


if __name__ == "__main__":
    main()
```

---

## 7. æµ‹è¯•éªŒè¯

### 7.1 å•å…ƒæµ‹è¯•

**æ–°å»ºæ–‡ä»¶**: `monai-label/tests/unit/test_nifti.py`

```python
import pytest
import tempfile
import numpy as np
import nibabel as nib
from pathlib import Path

from monailabel.datastore.local import LocalDatastore
from monailabel.endpoints.datastore import parse_nifti_header


class TestNIfTI:
    """NIfTIæ–‡ä»¶å¤„ç†æµ‹è¯•"""
    
    @pytest.fixture
    def sample_nifti(self):
        """åˆ›å»ºç¤ºä¾‹NIfTIæ–‡ä»¶"""
        with tempfile.NamedTemporaryFile(suffix='.nii.gz', delete=False) as f:
            # åˆ›å»º3Dæ•°æ®
            data = np.random.rand(64, 64, 32).astype(np.float32)
            
            # åˆ›å»ºNIfTIå›¾åƒ
            img = nib.Nifti1Image(data, np.eye(4))
            nib.save(img, f.name)
            
            return f.name
    
    def test_parse_nifti_header(self, sample_nifti):
        """æµ‹è¯•NIfTIå¤´ä¿¡æ¯è§£æ"""
        header_info = parse_nifti_header(Path(sample_nifti))
        
        assert header_info["dimensions"] == [64, 64, 32]
        assert header_info["datatype"] == 16  # DT_FLOAT
        assert "spacing" in header_info
    
    def test_nifti_datastore(self, sample_nifti, tmp_path):
        """æµ‹è¯•NIfTIæ•°æ®å­˜å‚¨"""
        datastore = LocalDatastore(str(tmp_path))
        
        # æ·»åŠ NIfTIæ–‡ä»¶
        metadata = {
            "name": "test.nii.gz",
            "modality": "CT",
        }
        image_id = datastore.add_nifti_image(Path(sample_nifti), metadata)
        
        assert image_id is not None
        
        # è·å–æ–‡ä»¶è·¯å¾„
        uri = datastore.get_image_uri(image_id)
        assert Path(uri).exists()
    
    def test_nifti_inference(self, sample_nifti):
        """æµ‹è¯•NIfTIæ¨ç†æµç¨‹"""
        from monailabel.tasks.infer.basic_infer import BasicInferTask
        
        # åˆ›å»ºæ¨ç†ä»»åŠ¡
        task = BasicInferTask(
            path=None,
            network=None,
            type="segmentation",
            labels=["organ"],
            dimension=3,
            description="Test NIfTI inference",
        )
        
        # å‡†å¤‡è¯·æ±‚
        request = {
            "model": "segmentation",
            "image": sample_nifti,
            "nninter": True,
            "pos_points": [[32, 32, 16]],
        }
        
        # æ‰§è¡Œæ¨ç†
        result_file, result_json = task(request)
        
        assert result_file is not None
        assert "nninter_elapsed" in result_json
```

### 7.2 é›†æˆæµ‹è¯•

**æµ‹è¯•æ­¥éª¤**:

```bash
# 1. å¯åŠ¨æœåŠ¡
docker compose up -d

# 2. ä¸Šä¼ æµ‹è¯•NIfTIæ–‡ä»¶
curl -X POST \
  http://localhost:8002/monai/datastore/nifti \
  -F "file=@Task03_Liver/imagesTr/liver_001.nii.gz" \
  -F "description=MSD Liver Test"

# 3. æŸ¥çœ‹æ–‡ä»¶åˆ—è¡¨
curl http://localhost:8002/monai/datastore/images?format=nifti

# 4. æ‰§è¡Œæ¨ç†
curl -X POST \
  http://localhost:8002/monai/infer/segmentation \
  -F "model=segmentation" \
  -F "image={file_id}" \
  -F 'params={"nninter": true, "pos_points": [[128, 128, 64]]}' \
  -F "output=dicom_seg"
```

---

## 8. æ€»ç»“

### ä¿®æ”¹æ–‡ä»¶æ¸…å•

| æ–‡ä»¶è·¯å¾„ | ä¿®æ”¹ç±»å‹ | è¯´æ˜ |
|---------|---------|------|
| `Viewers/extensions/cornerstone/src/components/DicomUpload/DicomUpload.tsx` | ä¿®æ”¹ | æ·»åŠ NIfTIä¸Šä¼ æ”¯æŒ |
| `Viewers/extensions/default/src/NIfTIDataSource/index.ts` | æ–°å»º | NIfTIæ•°æ®æº |
| `Viewers/extensions/default/src/NIfTIDataSource/createNIfTILoader.ts` | æ–°å»º | NIfTIåŠ è½½å™¨ |
| `Viewers/extensions/default/src/NIfTIDataSource/niftiParser.ts` | æ–°å»º | NIfTIè§£æå™¨ |
| `Viewers/platform/app/src/App.tsx` | ä¿®æ”¹ | æ³¨å†ŒNIfTIæ•°æ®æº |
| `monai-label/monailabel/endpoints/datastore.py` | ä¿®æ”¹ | æ·»åŠ NIfTIä¸Šä¼ ç«¯ç‚¹ |
| `monai-label/monailabel/tasks/infer/basic_infer.py` | ä¿®æ”¹ | æ·»åŠ NIfTIæ¨ç†æ”¯æŒ |
| `monai-label/monailabel/datastore/local.py` | ä¿®æ”¹ | æ‰©å±•NIfTIå­˜å‚¨ |
| `monai-label/monailabel/scripts/import_msd.py` | æ–°å»º | MSDæ‰¹é‡å¯¼å…¥å·¥å…· |

### å…³é”®ä¼˜åŠ¿

1. **æ— éœ€PACS**: ç›´æ¥ä¸Šä¼ NIfTIï¼Œæ— éœ€Orthancä¸­è½¬
2. **æ›´å¿«åŠ è½½**: æ— éœ€DICOMåˆ°NIfTIè½¬æ¢
3. **ä¿ç•™ç©ºé—´ä¿¡æ¯**: NIfTIçš„affineçŸ©é˜µå®Œæ•´ä¿ç•™
4. **æ‰¹é‡å¯¼å…¥**: æ”¯æŒMSDæ•°æ®é›†æ‰¹é‡å¯¼å…¥
5. **åŒå‘æ”¯æŒ**: åŒæ—¶æ”¯æŒDICOMå’ŒNIfTI

---

*æœ¬æ–‡æ¡£æä¾›äº†å®Œæ•´çš„NIfTIæ”¯æŒå®ç°æ–¹æ¡ˆï¼Œæ›´å¤šç»†èŠ‚è¯·å‚è€ƒå…·ä½“å®ç°ä»£ç *
